{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uLSY4xG5qIU"
   },
   "source": [
    "# A machine learning approach to improve RFID gate operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wanhv7y6CZw"
   },
   "source": [
    "## Basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T13:38:23.473972Z",
     "start_time": "2020-07-16T13:38:23.467344Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1448,
     "status": "ok",
     "timestamp": 1591567152691,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "xDoRN0Y45qIV",
    "outputId": "ccf30d17-9242-473a-a3bd-a1d5a93a7eb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bibliotecas necesarias\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuramos matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Semilla fija para reproducibilidad\n",
    "np.random.seed(1)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T13:38:40.550666Z",
     "start_time": "2020-07-16T13:38:40.331260Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 974,
     "status": "error",
     "timestamp": 1591567219615,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "vyN0Lv375qIb",
    "outputId": "f79af093-0b7e-43fd-bfe7-083870e6e2b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags1</th>\n",
       "      <th>prx1</th>\n",
       "      <th>prxcol1</th>\n",
       "      <th>tags2</th>\n",
       "      <th>prx2</th>\n",
       "      <th>prxcol2</th>\n",
       "      <th>tags3</th>\n",
       "      <th>prx3</th>\n",
       "      <th>prxcol3</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>read</th>\n",
       "      <th>ntags</th>\n",
       "      <th>ntagsread</th>\n",
       "      <th>t</th>\n",
       "      <th>L</th>\n",
       "      <th>deltax</th>\n",
       "      <th>deltay</th>\n",
       "      <th>ratioread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>57.370666</td>\n",
       "      <td>47.136963</td>\n",
       "      <td>33</td>\n",
       "      <td>85.475974</td>\n",
       "      <td>83.518197</td>\n",
       "      <td>25</td>\n",
       "      <td>52.815746</td>\n",
       "      <td>74.308925</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>0.38017</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.045695</td>\n",
       "      <td>0.120441</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>342.689869</td>\n",
       "      <td>175.303766</td>\n",
       "      <td>41</td>\n",
       "      <td>25.858434</td>\n",
       "      <td>20.239015</td>\n",
       "      <td>16</td>\n",
       "      <td>26.952245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>823</td>\n",
       "      <td>336</td>\n",
       "      <td>3.42749</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.537777</td>\n",
       "      <td>0.217907</td>\n",
       "      <td>0.408262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>12.713636</td>\n",
       "      <td>9.887868</td>\n",
       "      <td>28</td>\n",
       "      <td>883.634976</td>\n",
       "      <td>354.403516</td>\n",
       "      <td>6</td>\n",
       "      <td>56.289143</td>\n",
       "      <td>31.524838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>686</td>\n",
       "      <td>422</td>\n",
       "      <td>3.04516</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.971399</td>\n",
       "      <td>-0.231429</td>\n",
       "      <td>0.615160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>760.119673</td>\n",
       "      <td>389.551105</td>\n",
       "      <td>12</td>\n",
       "      <td>9.020537</td>\n",
       "      <td>8.547781</td>\n",
       "      <td>6</td>\n",
       "      <td>9.946548</td>\n",
       "      <td>10.464317</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>521</td>\n",
       "      <td>113</td>\n",
       "      <td>2.46165</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.015182</td>\n",
       "      <td>-0.137959</td>\n",
       "      <td>0.216891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>460.929094</td>\n",
       "      <td>424.343659</td>\n",
       "      <td>2</td>\n",
       "      <td>2.251396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "      <td>22.899492</td>\n",
       "      <td>21.818472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>0.87973</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.379577</td>\n",
       "      <td>0.017249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>32.326179</td>\n",
       "      <td>27.017891</td>\n",
       "      <td>31</td>\n",
       "      <td>335.763463</td>\n",
       "      <td>182.385486</td>\n",
       "      <td>24</td>\n",
       "      <td>33.853371</td>\n",
       "      <td>44.310590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>585</td>\n",
       "      <td>543</td>\n",
       "      <td>2.57785</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.523825</td>\n",
       "      <td>0.116696</td>\n",
       "      <td>0.928205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47</td>\n",
       "      <td>41.810212</td>\n",
       "      <td>29.840883</td>\n",
       "      <td>10</td>\n",
       "      <td>278.466763</td>\n",
       "      <td>137.373995</td>\n",
       "      <td>193</td>\n",
       "      <td>184.512026</td>\n",
       "      <td>184.230827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>958</td>\n",
       "      <td>958</td>\n",
       "      <td>3.19030</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.396206</td>\n",
       "      <td>0.144744</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>234.078506</td>\n",
       "      <td>166.124869</td>\n",
       "      <td>36</td>\n",
       "      <td>31.681251</td>\n",
       "      <td>23.486592</td>\n",
       "      <td>74</td>\n",
       "      <td>32.120123</td>\n",
       "      <td>26.429168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>0.94775</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.474664</td>\n",
       "      <td>-0.183170</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>310.608958</td>\n",
       "      <td>225.323499</td>\n",
       "      <td>33</td>\n",
       "      <td>27.139398</td>\n",
       "      <td>23.946196</td>\n",
       "      <td>25</td>\n",
       "      <td>19.803142</td>\n",
       "      <td>10.956988</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>235</td>\n",
       "      <td>1.35816</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.587279</td>\n",
       "      <td>-0.047222</td>\n",
       "      <td>0.679191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60</td>\n",
       "      <td>520.042280</td>\n",
       "      <td>328.811294</td>\n",
       "      <td>8</td>\n",
       "      <td>12.026846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>370.883397</td>\n",
       "      <td>319.738150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>0.65407</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.014063</td>\n",
       "      <td>0.067311</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tags1        prx1     prxcol1  tags2        prx2     prxcol2  tags3  \\\n",
       "0     35   57.370666   47.136963     33   85.475974   83.518197     25   \n",
       "1     17  342.689869  175.303766     41   25.858434   20.239015     16   \n",
       "2     16   12.713636    9.887868     28  883.634976  354.403516      6   \n",
       "3     34  760.119673  389.551105     12    9.020537    8.547781      6   \n",
       "4     64  460.929094  424.343659      2    2.251396    0.000000     96   \n",
       "5     36   32.326179   27.017891     31  335.763463  182.385486     24   \n",
       "6     47   41.810212   29.840883     10  278.466763  137.373995    193   \n",
       "7     55  234.078506  166.124869     36   31.681251   23.486592     74   \n",
       "8     59  310.608958  225.323499     33   27.139398   23.946196     25   \n",
       "9     60  520.042280  328.811294      8   12.026846    0.000000     58   \n",
       "\n",
       "         prx3     prxcol3  p1  p2  p3  read  ntags  ntagsread        t    L  \\\n",
       "0   52.815746   74.308925   0   1   0     1    121        121  0.38017  1.2   \n",
       "1   26.952245    0.000000   0   1   0     0    823        336  3.42749  1.2   \n",
       "2   56.289143   31.524838   0   0   1     0    686        422  3.04516  1.2   \n",
       "3    9.946548   10.464317   0   1   0     0    521        113  2.46165  1.2   \n",
       "4   22.899492   21.818472   0   0   1     1    280        280  0.87973  1.2   \n",
       "5   33.853371   44.310590   0   0   1     0    585        543  2.57785  1.2   \n",
       "6  184.512026  184.230827   0   1   0     1    958        958  3.19030  1.2   \n",
       "7   32.120123   26.429168   0   0   1     1    305        305  0.94775  1.2   \n",
       "8   19.803142   10.956988   0   1   0     0    346        235  1.35816  1.2   \n",
       "9  370.883397  319.738150   1   0   0     1    211        211  0.65407  1.2   \n",
       "\n",
       "     deltax    deltay  ratioread  \n",
       "0  0.045695  0.120441   1.000000  \n",
       "1 -0.537777  0.217907   0.408262  \n",
       "2  0.971399 -0.231429   0.615160  \n",
       "3 -1.015182 -0.137959   0.216891  \n",
       "4 -1.379577  0.017249   1.000000  \n",
       "5  0.523825  0.116696   0.928205  \n",
       "6  0.396206  0.144744   1.000000  \n",
       "7 -0.474664 -0.183170   1.000000  \n",
       "8 -0.587279 -0.047222   0.679191  \n",
       "9 -1.014063  0.067311   1.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "data = pandas.read_csv(\"batches.txt\") \n",
    "data[\"ratioread\"] = data.ntagsread/data.ntags\n",
    "data.shape\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T14:27:04.772786Z",
     "start_time": "2020-07-16T14:27:04.746807Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1591532219339,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "EyExRYEr5qIg",
    "outputId": "561085db-710c-4816-f41d-0a819fa80e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119978, 12) (119978,) (119978,) (119978,)\n"
     ]
    }
   ],
   "source": [
    "X=np.array(data[['tags1','prx1','prxcol1','tags2','prx2','prxcol2','tags3','prx3','prxcol3','p1','p2','p3']].values) # R=3\n",
    "#X=np.array(data[['tags1','prx1','prxcol1','tags2','prx2','prxcol2','p1','p2','p3']].values) # R=2\n",
    "# X=np.array(data[['tags1','prx1','prxcol1','p1','p2','p3']].values)  # R=1\n",
    "t=np.array(data.read.values)\n",
    "n=np.array(data.read.values)\n",
    "tI=np.array(data.t.values)\n",
    "print(X.shape,t.shape,n.shape,tI.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:03:55.049849Z",
     "start_time": "2020-07-16T11:29:10.364Z"
    }
   },
   "source": [
    "## Network layout definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T14:27:41.758708Z",
     "start_time": "2020-07-16T14:27:41.723652Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1591532221150,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "oxUeycP15qIi",
    "outputId": "56e369f7-25ce-463d-d099-efb6e36f5d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23996, 12) (23996,)\n",
      "[1 0 1 1 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos un autoencoder construido en keras\n",
    "import keras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, t_train, t_test, tI_train, tI_test =  train_test_split(X, t, tI, test_size=0.2)\n",
    "print(X_test.shape, tI_test.shape)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "standard_transformer = Pipeline(steps=[\n",
    "        ('standard', StandardScaler())])\n",
    "\n",
    "minmax_transformer = Pipeline(steps=[\n",
    "        ('minmax', MinMaxScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('std', standard_transformer , []),\n",
    "            ('mm', minmax_transformer , slice(1,9))\n",
    "        ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "#print(X_train[:10],X_test[:10])\n",
    "print(t_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T13:38:59.685654Z",
     "start_time": "2020-07-16T13:38:59.345188Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1769397,
     "status": "ok",
     "timestamp": 1591534017246,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "u8pGehWq5qIn",
    "outputId": "5e6acc40-cb3a-471d-f181-ed7bd55bda2f"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation=\"tanh\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.summary\n",
    "\n",
    "try: \n",
    "    model = keras.models.load_model(\"modelrfidR3_plm.h5\") # Load trained model\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training, run to retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=100, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"modelrfidR3.h5\", save_best_only=True)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, t_train, epochs=50000, \n",
    "                    validation_data=(X_test, t_test), \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "print(history.params)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics and graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:04:00.238455Z",
     "start_time": "2020-07-16T12:04:00.161629Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uNCZWjYfperL"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_csv_file = 'history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T13:39:07.887830Z",
     "start_time": "2020-07-16T13:39:04.819399Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1113,
     "status": "ok",
     "timestamp": 1591539628426,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "ddF8WlBR5qIq",
    "outputId": "9a2fa93b-060a-4f56-9d6f-55efd0ff597a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95982/95982 [==============================] - 2s 23us/step\n",
      "The score (accurary) in the training set is 95.04%\n",
      "23996/23996 [==============================] - 1s 21us/step\n",
      "The score (accuracy) in the test set is 95.03%\n",
      "\n",
      "[[11567   609]\n",
      " [  584 11236]]\n",
      "Recall: 94.86%\n",
      "Fall-out: 4.81%\n"
     ]
    }
   ],
   "source": [
    "print(f'The score (accurary) in the training set is {model.evaluate(X_train,t_train)[1]*100:.02f}%')\n",
    "print(f'The score (accuracy) in the test set is {model.evaluate(X_test,t_test)[1]*100:.02f}%\\n')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test = model.predict_classes(X_test)\n",
    "conf_mx = confusion_matrix(list(map(int,t_test)), y_test)\n",
    "print(conf_mx)\n",
    "print(f'Recall: {conf_mx[1,1]/(conf_mx[1,1]+conf_mx[0,1])*100:0.2f}%')\n",
    "print(f'Fall-out: {conf_mx[1,0]/(conf_mx[1,0]+conf_mx[0,0])*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T00:53:42.344778Z",
     "start_time": "2020-07-17T00:53:40.604442Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "faAjo5J_5qIu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7930, 12) (8194, 12) (7872, 12)\n",
      "23996/23996 [==============================] - 1s 28us/step\n",
      "All-policies accuracy is 94.86%\n",
      "\n",
      "[[11553   613]\n",
      " [  621 11209]]\n",
      "Recall: 94.81%\n",
      "Fall-out: 5.10%\n",
      "Precision: 94.75%\n",
      "\n",
      "7930/7930 [==============================] - 0s 22us/step\n",
      "Alpha-policy accuracy is 94.59%\n",
      "\n",
      "[[4429  195]\n",
      " [ 234 3072]]\n",
      "Recall: 94.03%\n",
      "Fall-out: 5.02%\n",
      "Precision: 92.92%\n",
      "\n",
      "8194/8194 [==============================] - 0s 22us/step\n",
      "Beta-policy accuracy is 94.73%\n",
      "\n",
      "[[4569  171]\n",
      " [ 261 3193]]\n",
      "Recall: 94.92%\n",
      "Fall-out: 5.40%\n",
      "Precision: 92.44%\n",
      "\n",
      "7872/7872 [==============================] - 0s 22us/step\n",
      "Gamma-policy accuracy is 95.26%\n",
      "\n",
      "[[2555  247]\n",
      " [ 126 4944]]\n",
      "Recall: 95.24%\n",
      "Fall-out: 4.70%\n",
      "Precision: 97.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Xt = X_test;\n",
    "tt = t_test;\n",
    "\n",
    "Xta = X_test[X_test[:,9]==1]\n",
    "tta = t_test[X_test[:,9]==1]\n",
    "\n",
    "Xtb = X_test[X_test[:,10]==1]\n",
    "ttb = t_test[X_test[:,10]==1]\n",
    "\n",
    "Xtg = X_test[X_test[:,11]==1]\n",
    "ttg = t_test[X_test[:,11]==1]\n",
    "\n",
    "print(Xta.shape, Xtb.shape, Xtg.shape)\n",
    "\n",
    "print(f'All-policies accuracy is {model.evaluate(Xt,tt)[1]*100:.02f}%\\n')\n",
    "yt = model.predict_classes(Xt)\n",
    "conf_mx = confusion_matrix(list(map(int,tt)), yt)\n",
    "print(conf_mx)\n",
    "print(f'Recall: {conf_mx[1,1]/(conf_mx[1,1]+conf_mx[0,1])*100:0.2f}%')\n",
    "print(f'Fall-out: {conf_mx[1,0]/(conf_mx[1,0]+conf_mx[0,0])*100:0.2f}%')\n",
    "precisionall = conf_mx[1,1]/(conf_mx[1,1]+conf_mx[1,0])\n",
    "print(f'Precision: {precisionall*100:0.2f}%\\n')\n",
    "\n",
    "print(f'Alpha-policy accuracy is {model.evaluate(Xta,tta)[1]*100:.02f}%\\n')\n",
    "yta = model.predict_classes(Xta)\n",
    "conf_mx = confusion_matrix(list(map(int,tta)), yta)\n",
    "print(conf_mx)\n",
    "print(f'Recall: {conf_mx[1,1]/(conf_mx[1,1]+conf_mx[0,1])*100:0.2f}%')\n",
    "print(f'Fall-out: {conf_mx[1,0]/(conf_mx[1,0]+conf_mx[0,0])*100:0.2f}%')\n",
    "precisiona = conf_mx[1,1]/(conf_mx[1,1]+conf_mx[1,0])\n",
    "print(f'Precision: {precisiona*100:0.2f}%\\n')\n",
    "\n",
    "print(f'Beta-policy accuracy is {model.evaluate(Xtb,ttb)[1]*100:.02f}%\\n')\n",
    "ytb = model.predict_classes(Xtb)\n",
    "conf_mx = confusion_matrix(list(map(int,ttb)), ytb)\n",
    "print(conf_mx)\n",
    "print(f'Recall: {conf_mx[1,1]/(conf_mx[1,1]+conf_mx[0,1])*100:0.2f}%')\n",
    "print(f'Fall-out: {conf_mx[1,0]/(conf_mx[1,0]+conf_mx[0,0])*100:0.2f}%')\n",
    "precisionb = conf_mx[1,1]/(conf_mx[1,1]+conf_mx[1,0])\n",
    "print(f'Precision: {precisionb*100:0.2f}%\\n')\n",
    "\n",
    "print(f'Gamma-policy accuracy is {model.evaluate(Xtg,ttg)[1]*100:.02f}%\\n')\n",
    "ytg = model.predict_classes(Xtg)\n",
    "conf_mx = confusion_matrix(list(map(int,ttg)), ytg)\n",
    "print(conf_mx)\n",
    "print(f'Recall: {conf_mx[1,1]/(conf_mx[1,1]+conf_mx[0,1])*100:0.2f}%')\n",
    "print(f'Fall-out: {conf_mx[1,0]/(conf_mx[1,0]+conf_mx[0,0])*100:0.2f}%')\n",
    "precisiong = conf_mx[1,1]/(conf_mx[1,1]+conf_mx[1,0])\n",
    "print(f'Precision: {precisiong*100:0.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator\n",
    "\n",
    "1. An ANN is created to predict the interrogation time expended given the batch signature\n",
    "2. The best policy is compared againts 3 static policies (alpha, beta and gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T23:46:17.190901Z",
     "start_time": "2020-07-16T23:46:16.431596Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1769397,
     "status": "ok",
     "timestamp": 1591534017246,
     "user": {
      "displayName": "Pablo L Matencio",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJHDBigWr81MeEBn-xboRsB26OHwNvE9DNDonfpg=s64",
      "userId": "10949236763923831331"
     },
     "user_tz": -120
    },
    "id": "u8pGehWq5qIn",
    "outputId": "5e6acc40-cb3a-471d-f181-ed7bd55bda2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23996/23996 [==============================] - 0s 20us/step\n",
      "The score (ratio rmse/meanIT) in the test set is 27.08%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0836891752792104"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltime = keras.models.Sequential([\n",
    "    keras.layers.Dense(20, activation=\"tanh\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1, activation=\"linear\")\n",
    "])\n",
    "\n",
    "modeltime.summary\n",
    "\n",
    "try: \n",
    "    modeltime = keras.models.load_model(\"modelrfidR3_time_plm.h5\") # Load trained model\n",
    "    print(f'The score (ratio rmse/meanIT) in the test set is {np.sqrt(modeltime.evaluate(X_test,tI_test))/np.mean(tI_test)*100:.2f}%\\n')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T23:44:22.873792Z",
     "start_time": "2020-07-16T23:43:19.903628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95982 samples, validate on 23996 samples\n",
      "Epoch 1/50\n",
      "95982/95982 [==============================] - 5s 56us/step - loss: 0.2819 - val_loss: 0.3217\n",
      "Epoch 2/50\n",
      "95982/95982 [==============================] - 5s 55us/step - loss: 0.2815 - val_loss: 0.3183\n",
      "Epoch 3/50\n",
      "95982/95982 [==============================] - 5s 55us/step - loss: 0.2815 - val_loss: 0.3187\n",
      "Epoch 4/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2817 - val_loss: 0.3194\n",
      "Epoch 5/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2812 - val_loss: 0.3279\n",
      "Epoch 6/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2816 - val_loss: 0.3188\n",
      "Epoch 7/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2813 - val_loss: 0.3189\n",
      "Epoch 8/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2815 - val_loss: 0.3221\n",
      "Epoch 9/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2811 - val_loss: 0.3208\n",
      "Epoch 10/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2816 - val_loss: 0.3196\n",
      "Epoch 11/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2810 - val_loss: 0.3190\n",
      "Epoch 12/50\n",
      "95982/95982 [==============================] - 5s 54us/step - loss: 0.2813 - val_loss: 0.3204\n",
      "{'batch_size': 32, 'epochs': 50, 'steps': None, 'samples': 95982, 'verbose': 1, 'do_validation': True, 'metrics': ['loss', 'val_loss']}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"modelrfidR3_time_plm.h5\", save_best_only=True)\n",
    "\n",
    "modeltime.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "historytime = modeltime.fit(X_train, tI_train, epochs=50, \n",
    "                    validation_data=(X_test, tI_test), \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "print(historytime.params)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(historytime.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIME SIMULATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T23:49:14.215631Z",
     "start_time": "2020-07-16T23:49:10.040493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0, 0, 0, 0\n",
      "1, 1, 1, 0, 1\n",
      "2, 2, 1, 1, 1\n",
      "3, 3, 1, 2, 1\n",
      "4, 4, 2, 3, 2\n",
      "5, 5, 2, 4, 3\n",
      "6, 6, 2, 5, 3\n",
      "7, 7, 2, 5, 3\n",
      "8, 8, 2, 6, 4\n",
      "9, 9, 2, 7, 5\n",
      "10, 10, 3, 7, 6\n",
      "11, 11, 3, 8, 7\n",
      "12, 12, 4, 8, 8\n",
      "13, 12, 4, 8, 8\n",
      "14, 13, 5, 8, 9\n",
      "15, 14, 5, 9, 9\n",
      "16, 14, 5, 9, 9\n",
      "17, 15, 6, 9, 9\n",
      "18, 16, 6, 9, 10\n",
      "19, 17, 6, 9, 11\n",
      "20, 18, 7, 9, 12\n",
      "21, 18, 7, 9, 12\n",
      "22, 19, 8, 9, 13\n",
      "23, 20, 9, 9, 14\n",
      "24, 21, 10, 9, 15\n",
      "25, 22, 11, 9, 16\n",
      "26, 23, 12, 9, 17\n",
      "27, 23, 12, 10, 17\n",
      "28, 24, 13, 11, 18\n",
      "29, 25, 14, 12, 19\n",
      "30, 26, 14, 13, 19\n",
      "31, 26, 14, 14, 19\n",
      "32, 26, 14, 14, 19\n",
      "33, 27, 15, 14, 20\n",
      "34, 28, 15, 14, 21\n",
      "35, 29, 15, 15, 22\n",
      "36, 30, 15, 15, 22\n",
      "37, 31, 15, 16, 22\n",
      "38, 31, 15, 16, 22\n",
      "39, 31, 15, 17, 22\n",
      "40, 32, 16, 17, 23\n",
      "41, 33, 17, 17, 24\n",
      "42, 34, 18, 17, 24\n",
      "43, 35, 19, 17, 25\n",
      "44, 36, 19, 18, 25\n",
      "45, 37, 19, 19, 25\n",
      "46, 38, 19, 19, 26\n",
      "47, 38, 19, 19, 26\n",
      "48, 39, 19, 19, 26\n",
      "49, 40, 20, 19, 27\n",
      "50, 41, 21, 20, 28\n",
      "51, 41, 22, 21, 29\n",
      "52, 42, 23, 21, 30\n",
      "53, 43, 23, 22, 30\n",
      "54, 44, 24, 23, 30\n",
      "55, 45, 25, 23, 31\n",
      "56, 46, 26, 24, 32\n",
      "57, 47, 26, 25, 32\n",
      "58, 47, 26, 25, 32\n",
      "59, 47, 26, 26, 33\n",
      "60, 47, 26, 26, 33\n",
      "61, 48, 26, 27, 34\n",
      "62, 49, 27, 27, 35\n",
      "63, 50, 28, 27, 36\n",
      "64, 51, 29, 27, 37\n",
      "65, 52, 29, 28, 38\n",
      "66, 53, 30, 28, 39\n",
      "67, 54, 30, 28, 40\n",
      "68, 55, 31, 29, 41\n",
      "69, 56, 31, 29, 41\n",
      "70, 57, 32, 29, 42\n",
      "71, 57, 32, 30, 43\n",
      "72, 58, 33, 30, 44\n",
      "73, 59, 33, 30, 45\n",
      "74, 60, 34, 31, 45\n",
      "75, 61, 34, 32, 45\n",
      "76, 62, 35, 33, 46\n",
      "77, 63, 36, 34, 46\n",
      "78, 64, 36, 34, 47\n",
      "79, 65, 37, 35, 47\n",
      "80, 66, 38, 36, 48\n",
      "81, 67, 39, 36, 49\n",
      "82, 68, 40, 36, 50\n",
      "83, 69, 40, 36, 50\n",
      "84, 70, 41, 36, 51\n",
      "85, 71, 42, 37, 52\n",
      "86, 72, 43, 38, 53\n",
      "87, 73, 44, 38, 54\n",
      "88, 74, 45, 39, 54\n",
      "89, 75, 45, 40, 54\n",
      "90, 76, 45, 41, 54\n",
      "91, 77, 45, 41, 55\n",
      "92, 78, 46, 41, 56\n",
      "93, 79, 46, 42, 56\n",
      "94, 80, 46, 42, 56\n",
      "95, 80, 46, 42, 56\n",
      "96, 81, 47, 42, 57\n",
      "97, 82, 47, 43, 58\n",
      "98, 82, 47, 43, 59\n",
      "99, 83, 48, 43, 60\n",
      "100, 84, 48, 43, 60\n",
      "101, 85, 49, 43, 61\n",
      "102, 86, 49, 43, 62\n",
      "103, 87, 49, 44, 63\n",
      "104, 88, 50, 44, 64\n",
      "105, 89, 50, 45, 65\n",
      "106, 89, 51, 45, 66\n",
      "107, 89, 51, 45, 66\n",
      "108, 90, 52, 45, 67\n",
      "109, 91, 52, 45, 68\n",
      "110, 92, 53, 45, 69\n",
      "111, 93, 53, 45, 70\n",
      "112, 94, 54, 45, 71\n",
      "113, 94, 54, 45, 71\n",
      "114, 95, 54, 46, 72\n",
      "115, 96, 54, 47, 72\n",
      "116, 97, 54, 48, 72\n",
      "117, 98, 54, 48, 73\n",
      "118, 99, 54, 48, 74\n",
      "119, 100, 54, 48, 75\n",
      "120, 101, 55, 48, 76\n",
      "121, 102, 55, 49, 77\n",
      "122, 103, 56, 49, 78\n",
      "123, 104, 56, 50, 79\n",
      "124, 105, 56, 50, 80\n",
      "125, 106, 56, 51, 81\n",
      "126, 107, 56, 52, 82\n",
      "127, 108, 56, 52, 82\n",
      "128, 108, 56, 52, 82\n",
      "129, 109, 57, 52, 83\n",
      "130, 110, 57, 53, 83\n",
      "131, 111, 58, 53, 84\n",
      "132, 112, 58, 54, 84\n",
      "133, 113, 58, 55, 84\n",
      "134, 114, 58, 56, 84\n",
      "135, 115, 59, 56, 85\n",
      "136, 116, 59, 57, 85\n",
      "137, 116, 59, 57, 85\n",
      "138, 117, 59, 57, 86\n",
      "139, 118, 60, 57, 86\n",
      "140, 119, 60, 58, 87\n",
      "141, 120, 60, 59, 87\n",
      "142, 120, 60, 60, 88\n",
      "143, 121, 60, 61, 88\n",
      "144, 122, 61, 61, 89\n",
      "145, 123, 62, 61, 90\n",
      "146, 123, 62, 61, 90\n",
      "147, 124, 63, 62, 91\n",
      "148, 125, 64, 62, 92\n",
      "149, 126, 65, 62, 93\n",
      "150, 127, 66, 63, 94\n",
      "151, 128, 67, 63, 95\n",
      "152, 129, 68, 63, 96\n",
      "153, 130, 69, 63, 97\n",
      "154, 131, 69, 63, 98\n",
      "155, 132, 69, 63, 99\n",
      "156, 133, 70, 63, 100\n",
      "157, 134, 70, 63, 101\n",
      "158, 134, 70, 63, 101\n",
      "159, 135, 70, 64, 101\n",
      "160, 136, 70, 65, 102\n",
      "161, 137, 70, 65, 103\n",
      "162, 138, 71, 65, 104\n",
      "163, 139, 71, 65, 105\n",
      "164, 140, 72, 65, 106\n",
      "165, 141, 73, 65, 106\n",
      "166, 142, 74, 66, 107\n",
      "167, 143, 75, 66, 108\n",
      "168, 144, 76, 67, 109\n",
      "169, 145, 77, 68, 109\n",
      "170, 145, 77, 68, 109\n",
      "171, 146, 78, 68, 109\n",
      "172, 147, 79, 69, 110\n",
      "173, 148, 79, 69, 111\n",
      "174, 149, 80, 70, 112\n",
      "175, 150, 81, 70, 113\n",
      "176, 151, 82, 71, 114\n",
      "177, 152, 82, 72, 115\n",
      "178, 153, 82, 73, 115\n",
      "179, 154, 83, 74, 115\n",
      "180, 155, 83, 74, 116\n",
      "181, 155, 83, 75, 116\n",
      "182, 156, 84, 76, 116\n",
      "183, 157, 84, 77, 117\n",
      "184, 158, 85, 78, 118\n",
      "185, 159, 85, 78, 119\n",
      "186, 160, 85, 78, 120\n",
      "187, 161, 86, 79, 121\n",
      "188, 162, 86, 79, 122\n",
      "189, 163, 87, 80, 123\n",
      "190, 164, 87, 81, 124\n",
      "191, 165, 87, 82, 124\n",
      "192, 166, 88, 82, 125\n",
      "193, 167, 88, 83, 125\n",
      "194, 168, 88, 84, 125\n",
      "195, 169, 88, 85, 126\n",
      "196, 170, 88, 86, 126\n",
      "197, 170, 88, 86, 126\n",
      "198, 171, 89, 86, 127\n",
      "199, 172, 90, 86, 128\n",
      "200, 172, 90, 86, 128\n",
      "201, 173, 90, 86, 129\n",
      "202, 174, 91, 86, 130\n",
      "203, 174, 91, 86, 131\n",
      "204, 175, 92, 86, 132\n",
      "205, 175, 92, 86, 132\n",
      "206, 176, 92, 87, 132\n",
      "207, 177, 92, 88, 133\n",
      "208, 178, 92, 88, 134\n",
      "209, 179, 93, 89, 135\n",
      "210, 180, 94, 89, 136\n",
      "211, 181, 95, 90, 137\n",
      "212, 182, 96, 90, 138\n",
      "213, 183, 96, 91, 138\n",
      "214, 184, 96, 92, 139\n",
      "215, 184, 96, 92, 139\n",
      "216, 185, 97, 93, 140\n",
      "217, 186, 98, 93, 141\n",
      "218, 186, 98, 94, 142\n",
      "219, 187, 99, 94, 143\n",
      "220, 188, 99, 95, 143\n",
      "221, 189, 100, 96, 144\n",
      "222, 190, 100, 97, 145\n",
      "223, 191, 101, 97, 146\n",
      "224, 192, 101, 97, 147\n",
      "225, 193, 101, 98, 147\n",
      "226, 194, 102, 98, 148\n",
      "227, 195, 103, 99, 149\n",
      "228, 195, 103, 99, 149\n",
      "229, 196, 103, 99, 150\n",
      "230, 197, 103, 100, 150\n",
      "231, 198, 103, 101, 151\n",
      "232, 199, 104, 101, 152\n",
      "233, 200, 105, 101, 153\n",
      "234, 201, 105, 101, 154\n",
      "235, 201, 105, 101, 154\n",
      "236, 201, 105, 101, 154\n",
      "237, 202, 105, 102, 155\n",
      "238, 202, 105, 102, 155\n",
      "239, 203, 105, 102, 155\n",
      "240, 204, 106, 103, 156\n",
      "241, 204, 107, 104, 157\n",
      "242, 204, 107, 104, 157\n",
      "243, 205, 107, 104, 158\n",
      "244, 205, 107, 105, 158\n",
      "245, 206, 108, 105, 158\n",
      "246, 207, 109, 105, 159\n",
      "247, 207, 109, 105, 159\n",
      "248, 208, 110, 106, 160\n",
      "249, 208, 110, 106, 160\n",
      "250, 208, 110, 106, 160\n",
      "251, 209, 110, 107, 160\n",
      "252, 210, 110, 108, 161\n",
      "253, 211, 111, 109, 162\n",
      "254, 211, 112, 110, 163\n",
      "255, 211, 112, 110, 163\n",
      "256, 212, 112, 110, 164\n",
      "257, 213, 112, 111, 165\n",
      "258, 214, 113, 112, 166\n",
      "259, 215, 114, 112, 167\n",
      "260, 216, 114, 112, 168\n",
      "261, 217, 114, 113, 168\n",
      "262, 218, 115, 113, 169\n",
      "263, 219, 116, 113, 170\n",
      "264, 220, 116, 114, 170\n",
      "265, 221, 117, 114, 171\n",
      "266, 222, 118, 114, 172\n",
      "267, 223, 118, 115, 172\n",
      "268, 224, 119, 116, 173\n",
      "269, 224, 119, 116, 173\n",
      "270, 225, 120, 116, 174\n",
      "271, 226, 120, 117, 174\n",
      "272, 227, 120, 117, 175\n",
      "273, 228, 120, 117, 176\n",
      "274, 228, 120, 117, 176\n",
      "275, 228, 120, 117, 177\n",
      "276, 228, 120, 117, 177\n",
      "277, 229, 121, 118, 178\n",
      "278, 230, 121, 119, 178\n",
      "279, 231, 121, 120, 179\n",
      "280, 232, 122, 121, 180\n",
      "281, 233, 122, 122, 181\n",
      "282, 234, 122, 123, 181\n",
      "283, 234, 122, 123, 181\n",
      "284, 235, 122, 124, 181\n",
      "285, 236, 122, 124, 182\n",
      "286, 237, 123, 125, 183\n",
      "287, 238, 123, 125, 184\n",
      "288, 239, 123, 125, 185\n",
      "289, 240, 124, 125, 186\n",
      "290, 240, 125, 125, 187\n",
      "291, 241, 126, 126, 188\n",
      "292, 242, 127, 126, 189\n",
      "293, 242, 127, 126, 190\n",
      "294, 242, 127, 126, 190\n",
      "295, 243, 127, 127, 190\n",
      "296, 243, 127, 127, 190\n",
      "297, 243, 127, 127, 190\n",
      "298, 244, 128, 128, 191\n",
      "299, 245, 128, 129, 192\n",
      "300, 246, 129, 129, 193\n",
      "301, 247, 130, 130, 193\n",
      "302, 248, 131, 130, 194\n",
      "303, 248, 131, 130, 194\n",
      "304, 248, 131, 130, 194\n",
      "305, 249, 131, 130, 195\n",
      "306, 250, 131, 131, 195\n",
      "307, 250, 131, 131, 195\n",
      "308, 251, 132, 131, 196\n",
      "309, 252, 132, 132, 196\n",
      "310, 253, 132, 132, 197\n",
      "311, 254, 132, 132, 198\n",
      "312, 255, 132, 133, 198\n",
      "313, 256, 132, 134, 198\n",
      "314, 256, 132, 134, 198\n",
      "315, 257, 133, 134, 199\n",
      "316, 258, 134, 135, 200\n",
      "317, 259, 134, 136, 200\n",
      "318, 259, 134, 136, 200\n",
      "319, 260, 135, 136, 200\n",
      "320, 261, 135, 137, 200\n",
      "321, 262, 136, 137, 201\n",
      "322, 263, 136, 137, 201\n",
      "323, 263, 136, 137, 202\n",
      "324, 264, 137, 137, 203\n",
      "325, 264, 137, 137, 203\n",
      "326, 265, 137, 137, 204\n",
      "327, 265, 137, 137, 204\n",
      "328, 266, 138, 138, 205\n",
      "329, 267, 138, 138, 206\n",
      "330, 268, 138, 138, 206\n",
      "331, 268, 138, 138, 206\n",
      "332, 269, 139, 138, 207\n",
      "333, 269, 139, 138, 208\n",
      "334, 270, 140, 139, 209\n",
      "335, 271, 141, 140, 210\n",
      "336, 272, 141, 141, 211\n",
      "337, 273, 141, 141, 212\n",
      "338, 274, 141, 142, 212\n",
      "339, 275, 142, 142, 213\n",
      "340, 276, 143, 142, 214\n",
      "341, 277, 144, 143, 214\n",
      "342, 277, 144, 143, 214\n",
      "343, 278, 144, 144, 214\n",
      "344, 279, 144, 144, 214\n",
      "345, 280, 145, 144, 215\n",
      "346, 281, 146, 144, 216\n",
      "347, 282, 147, 145, 217\n",
      "348, 283, 147, 145, 218\n",
      "349, 284, 147, 146, 219\n",
      "350, 285, 148, 146, 220\n",
      "351, 286, 149, 146, 221\n",
      "352, 287, 150, 146, 222\n",
      "353, 288, 151, 146, 222\n",
      "354, 289, 152, 146, 223\n",
      "355, 289, 152, 147, 223\n",
      "356, 290, 153, 147, 224\n",
      "357, 291, 153, 147, 224\n",
      "358, 292, 153, 147, 225\n",
      "359, 293, 154, 148, 225\n",
      "360, 294, 155, 148, 226\n",
      "361, 295, 156, 149, 227\n",
      "362, 295, 156, 150, 227\n",
      "363, 296, 156, 150, 227\n",
      "364, 297, 157, 151, 228\n",
      "365, 298, 157, 152, 228\n",
      "366, 299, 158, 152, 229\n",
      "367, 300, 159, 152, 230\n",
      "368, 301, 160, 152, 231\n",
      "369, 301, 160, 153, 232\n",
      "370, 302, 160, 153, 232\n",
      "371, 302, 160, 153, 233\n",
      "372, 303, 160, 153, 234\n",
      "373, 304, 160, 154, 234\n",
      "374, 305, 161, 154, 235\n",
      "375, 306, 161, 155, 236\n",
      "376, 307, 161, 155, 237\n",
      "377, 308, 162, 156, 238\n",
      "378, 309, 162, 156, 239\n",
      "379, 310, 163, 157, 240\n",
      "380, 311, 164, 157, 241\n",
      "381, 312, 165, 158, 242\n",
      "382, 313, 166, 159, 243\n",
      "383, 314, 166, 159, 244\n",
      "384, 315, 167, 159, 245\n",
      "385, 316, 168, 159, 246\n",
      "386, 317, 168, 160, 246\n",
      "387, 318, 169, 160, 247\n",
      "388, 318, 169, 161, 247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389, 318, 169, 161, 247\n",
      "390, 319, 170, 162, 248\n",
      "391, 320, 170, 163, 248\n",
      "392, 321, 171, 164, 249\n",
      "393, 322, 172, 165, 250\n",
      "394, 322, 172, 166, 251\n",
      "395, 323, 172, 167, 252\n",
      "396, 324, 173, 167, 252\n",
      "397, 324, 173, 168, 252\n",
      "398, 325, 173, 168, 253\n",
      "399, 325, 174, 169, 254\n",
      "400, 326, 175, 169, 255\n",
      "401, 327, 176, 169, 256\n",
      "402, 328, 177, 169, 257\n",
      "403, 329, 178, 169, 258\n",
      "404, 330, 179, 169, 259\n",
      "405, 331, 180, 169, 260\n",
      "406, 332, 180, 169, 261\n",
      "407, 332, 180, 169, 261\n",
      "408, 333, 181, 170, 262\n",
      "409, 334, 182, 170, 263\n",
      "410, 335, 182, 171, 263\n",
      "411, 336, 183, 171, 264\n",
      "412, 337, 184, 172, 264\n",
      "413, 338, 185, 172, 265\n",
      "414, 339, 185, 172, 266\n",
      "415, 340, 185, 173, 267\n",
      "416, 341, 186, 173, 268\n",
      "417, 342, 187, 173, 269\n",
      "418, 343, 188, 173, 270\n",
      "419, 344, 188, 174, 271\n",
      "420, 345, 189, 174, 272\n",
      "421, 346, 190, 175, 273\n",
      "422, 347, 190, 176, 273\n",
      "423, 347, 190, 176, 273\n",
      "424, 348, 191, 176, 274\n",
      "425, 349, 192, 176, 275\n",
      "426, 350, 193, 177, 276\n",
      "427, 350, 193, 177, 276\n",
      "428, 351, 193, 178, 277\n",
      "429, 352, 193, 179, 277\n",
      "430, 353, 193, 179, 278\n",
      "431, 354, 194, 179, 279\n",
      "432, 355, 195, 179, 280\n",
      "433, 355, 195, 180, 280\n",
      "434, 356, 195, 180, 281\n",
      "435, 357, 195, 181, 281\n",
      "436, 358, 195, 181, 282\n",
      "437, 359, 195, 181, 283\n",
      "438, 360, 196, 182, 284\n",
      "439, 361, 196, 183, 284\n",
      "440, 361, 196, 183, 284\n",
      "441, 362, 197, 184, 285\n",
      "442, 363, 197, 185, 285\n",
      "443, 363, 197, 186, 286\n",
      "444, 364, 197, 187, 287\n",
      "445, 365, 197, 188, 288\n",
      "446, 366, 197, 189, 289\n",
      "447, 367, 198, 189, 290\n",
      "448, 368, 198, 189, 291\n",
      "449, 368, 198, 189, 291\n",
      "450, 369, 199, 189, 291\n",
      "451, 370, 200, 189, 292\n",
      "452, 371, 200, 190, 293\n",
      "453, 372, 201, 190, 294\n",
      "454, 372, 201, 191, 294\n",
      "455, 373, 201, 192, 294\n",
      "456, 373, 201, 192, 294\n",
      "457, 374, 201, 193, 295\n",
      "458, 375, 201, 193, 295\n",
      "459, 376, 202, 194, 296\n",
      "460, 377, 203, 195, 297\n",
      "461, 377, 203, 196, 297\n",
      "462, 378, 204, 197, 297\n",
      "463, 379, 205, 198, 298\n",
      "464, 380, 205, 199, 298\n",
      "465, 381, 205, 200, 298\n",
      "466, 382, 206, 200, 299\n",
      "467, 383, 207, 200, 300\n",
      "468, 384, 208, 200, 301\n",
      "469, 385, 209, 200, 302\n",
      "470, 385, 209, 200, 303\n",
      "471, 386, 209, 200, 304\n",
      "472, 387, 209, 201, 305\n",
      "473, 388, 210, 201, 306\n",
      "474, 389, 211, 201, 307\n",
      "475, 390, 212, 202, 308\n",
      "476, 391, 212, 203, 309\n",
      "477, 392, 213, 203, 310\n",
      "478, 393, 214, 203, 311\n",
      "479, 394, 214, 204, 311\n",
      "480, 395, 214, 205, 312\n",
      "481, 396, 214, 206, 313\n",
      "482, 397, 215, 206, 314\n",
      "483, 398, 216, 207, 315\n",
      "484, 399, 216, 207, 315\n",
      "485, 400, 217, 208, 315\n",
      "486, 401, 218, 209, 316\n",
      "487, 402, 218, 209, 316\n",
      "488, 403, 219, 209, 317\n",
      "489, 404, 219, 209, 318\n",
      "490, 405, 219, 210, 318\n",
      "491, 405, 219, 211, 318\n",
      "492, 406, 220, 211, 319\n",
      "493, 406, 220, 211, 319\n",
      "494, 407, 221, 212, 320\n",
      "495, 407, 221, 212, 321\n",
      "496, 408, 221, 212, 322\n",
      "497, 409, 222, 212, 323\n",
      "498, 410, 222, 212, 323\n",
      "499, 411, 222, 213, 323\n",
      "500, 412, 222, 213, 324\n",
      "501, 413, 223, 213, 325\n",
      "502, 413, 223, 214, 325\n",
      "503, 413, 223, 214, 325\n",
      "504, 414, 224, 214, 325\n",
      "505, 415, 224, 215, 326\n",
      "506, 416, 225, 215, 327\n",
      "507, 417, 225, 216, 328\n",
      "508, 418, 226, 217, 329\n",
      "509, 418, 226, 217, 330\n",
      "510, 419, 227, 218, 331\n",
      "511, 420, 228, 219, 332\n",
      "512, 421, 228, 220, 332\n",
      "513, 421, 228, 220, 333\n",
      "514, 422, 229, 220, 334\n",
      "515, 423, 229, 221, 335\n",
      "516, 424, 230, 221, 336\n",
      "517, 425, 230, 222, 336\n",
      "518, 426, 230, 222, 337\n",
      "519, 427, 231, 223, 338\n",
      "520, 428, 232, 224, 339\n",
      "521, 429, 232, 224, 340\n",
      "522, 430, 232, 224, 341\n",
      "523, 430, 232, 224, 342\n",
      "524, 431, 233, 224, 343\n",
      "525, 432, 234, 224, 344\n",
      "526, 433, 235, 225, 345\n",
      "527, 434, 236, 225, 346\n",
      "528, 435, 236, 225, 347\n",
      "529, 436, 237, 225, 348\n",
      "530, 437, 238, 226, 349\n",
      "531, 438, 238, 227, 349\n",
      "532, 438, 238, 227, 349\n",
      "533, 439, 238, 227, 350\n",
      "534, 439, 238, 227, 351\n",
      "535, 440, 239, 227, 352\n",
      "536, 440, 239, 227, 352\n",
      "537, 440, 239, 227, 353\n",
      "538, 440, 239, 227, 354\n",
      "539, 441, 240, 227, 355\n",
      "540, 442, 241, 228, 356\n",
      "541, 443, 242, 228, 357\n",
      "542, 443, 242, 228, 357\n",
      "543, 443, 242, 228, 357\n",
      "544, 443, 243, 229, 358\n",
      "545, 443, 243, 229, 358\n",
      "546, 444, 243, 230, 359\n",
      "547, 445, 243, 231, 359\n",
      "548, 446, 243, 231, 360\n",
      "549, 447, 243, 231, 361\n",
      "550, 448, 243, 232, 362\n",
      "551, 448, 243, 232, 363\n",
      "552, 449, 244, 232, 364\n",
      "553, 449, 244, 233, 364\n",
      "554, 450, 244, 234, 364\n",
      "555, 451, 245, 234, 365\n",
      "556, 452, 245, 234, 366\n",
      "557, 453, 246, 234, 367\n",
      "558, 453, 246, 234, 367\n",
      "559, 453, 246, 234, 367\n",
      "560, 453, 246, 234, 367\n",
      "561, 454, 246, 234, 368\n",
      "562, 455, 246, 234, 369\n",
      "563, 456, 247, 234, 370\n",
      "564, 457, 248, 235, 371\n",
      "565, 458, 249, 235, 372\n",
      "566, 458, 249, 235, 372\n",
      "567, 458, 249, 236, 373\n",
      "568, 459, 250, 237, 374\n",
      "569, 460, 251, 238, 374\n",
      "570, 461, 252, 238, 375\n",
      "571, 462, 252, 238, 375\n",
      "572, 463, 252, 239, 376\n",
      "573, 464, 253, 240, 377\n",
      "574, 464, 253, 240, 377\n",
      "575, 465, 254, 240, 377\n",
      "576, 466, 255, 241, 378\n",
      "577, 466, 255, 241, 378\n",
      "578, 467, 256, 242, 379\n",
      "579, 467, 257, 242, 379\n",
      "580, 468, 258, 242, 380\n",
      "581, 469, 259, 243, 381\n",
      "582, 470, 260, 243, 382\n",
      "583, 471, 261, 244, 383\n",
      "584, 472, 261, 245, 383\n",
      "585, 473, 262, 245, 384\n",
      "586, 474, 263, 246, 385\n",
      "587, 475, 263, 247, 385\n",
      "588, 476, 263, 247, 386\n",
      "589, 477, 264, 248, 387\n",
      "590, 477, 264, 248, 387\n",
      "591, 478, 265, 248, 388\n",
      "592, 479, 266, 248, 389\n",
      "593, 480, 267, 248, 390\n",
      "594, 481, 268, 248, 391\n",
      "595, 481, 268, 248, 391\n",
      "596, 482, 269, 248, 392\n",
      "597, 483, 270, 248, 393\n",
      "598, 484, 271, 248, 394\n",
      "599, 485, 272, 248, 395\n",
      "600, 485, 272, 249, 396\n",
      "601, 486, 273, 249, 397\n",
      "602, 487, 274, 249, 397\n",
      "603, 488, 274, 250, 398\n",
      "604, 489, 274, 251, 399\n",
      "605, 489, 274, 251, 400\n",
      "606, 490, 274, 252, 400\n",
      "607, 491, 274, 253, 401\n",
      "608, 492, 275, 253, 402\n",
      "609, 493, 276, 253, 403\n",
      "610, 493, 276, 253, 404\n",
      "611, 494, 277, 253, 404\n",
      "612, 495, 277, 253, 405\n",
      "613, 496, 278, 253, 406\n",
      "614, 497, 278, 253, 407\n",
      "615, 497, 278, 253, 407\n",
      "616, 498, 279, 253, 407\n",
      "617, 499, 280, 253, 408\n",
      "618, 500, 281, 253, 409\n",
      "619, 500, 281, 253, 409\n",
      "620, 501, 281, 254, 409\n",
      "621, 502, 282, 254, 410\n",
      "622, 502, 282, 254, 410\n",
      "623, 502, 282, 255, 411\n",
      "624, 503, 282, 256, 411\n",
      "625, 504, 282, 256, 411\n",
      "626, 505, 283, 257, 412\n",
      "627, 506, 283, 258, 413\n",
      "628, 506, 283, 259, 413\n",
      "629, 507, 283, 260, 414\n",
      "630, 508, 283, 261, 415\n",
      "631, 509, 284, 262, 416\n",
      "632, 510, 284, 262, 416\n",
      "633, 511, 285, 262, 417\n",
      "634, 512, 286, 263, 418\n",
      "635, 513, 286, 263, 418\n",
      "636, 513, 287, 263, 419\n",
      "637, 514, 288, 263, 420\n",
      "638, 515, 288, 264, 420\n",
      "639, 516, 289, 265, 421\n",
      "640, 517, 290, 265, 422\n",
      "641, 518, 290, 266, 422\n",
      "642, 519, 291, 266, 422\n",
      "643, 519, 291, 266, 422\n",
      "644, 520, 291, 267, 423\n",
      "645, 521, 291, 267, 423\n",
      "646, 522, 292, 267, 424\n",
      "647, 523, 292, 267, 425\n",
      "648, 524, 293, 267, 426\n",
      "649, 525, 294, 267, 427\n",
      "650, 526, 294, 267, 428\n",
      "651, 527, 295, 267, 429\n",
      "652, 527, 295, 267, 429\n",
      "653, 528, 295, 268, 429\n",
      "654, 529, 296, 268, 430\n",
      "655, 530, 296, 269, 430\n",
      "656, 530, 296, 269, 430\n",
      "657, 530, 296, 269, 430\n",
      "658, 531, 297, 269, 431\n",
      "659, 532, 297, 270, 431\n",
      "660, 533, 298, 271, 432\n",
      "661, 534, 298, 272, 433\n",
      "662, 534, 298, 273, 433\n",
      "663, 535, 299, 273, 434\n",
      "664, 536, 300, 273, 434\n",
      "665, 537, 300, 274, 434\n",
      "666, 538, 301, 275, 435\n",
      "667, 538, 301, 275, 436\n",
      "668, 538, 301, 275, 437\n",
      "669, 539, 302, 275, 438\n",
      "670, 540, 302, 276, 439\n",
      "671, 540, 302, 276, 439\n",
      "672, 541, 303, 276, 440\n",
      "673, 542, 304, 277, 441\n",
      "674, 542, 304, 278, 441\n",
      "675, 543, 304, 279, 441\n",
      "676, 544, 305, 280, 442\n",
      "677, 545, 306, 280, 443\n",
      "678, 546, 307, 280, 444\n",
      "679, 546, 307, 280, 444\n",
      "680, 547, 308, 280, 444\n",
      "681, 548, 309, 281, 445\n",
      "682, 549, 309, 282, 445\n",
      "683, 549, 309, 282, 445\n",
      "684, 549, 309, 282, 446\n",
      "685, 550, 310, 283, 447\n",
      "686, 551, 310, 284, 447\n",
      "687, 552, 311, 285, 448\n",
      "688, 552, 312, 286, 449\n",
      "689, 553, 313, 287, 450\n",
      "690, 554, 313, 287, 450\n",
      "691, 555, 313, 287, 451\n",
      "692, 556, 314, 287, 452\n",
      "693, 557, 315, 288, 453\n",
      "694, 558, 315, 289, 453\n",
      "695, 559, 315, 289, 454\n",
      "696, 560, 316, 289, 455\n",
      "697, 561, 317, 289, 456\n",
      "698, 562, 318, 290, 457\n",
      "699, 563, 319, 290, 458\n",
      "700, 564, 319, 290, 459\n",
      "701, 564, 319, 291, 459\n",
      "702, 564, 319, 291, 459\n",
      "703, 564, 319, 291, 459\n",
      "704, 565, 319, 292, 459\n",
      "705, 565, 319, 293, 459\n",
      "706, 566, 319, 294, 459\n",
      "707, 566, 319, 294, 460\n",
      "708, 566, 319, 294, 460\n",
      "709, 567, 320, 294, 461\n",
      "710, 568, 321, 294, 462\n",
      "711, 569, 321, 294, 463\n",
      "712, 570, 322, 294, 464\n",
      "713, 571, 322, 295, 464\n",
      "714, 572, 323, 296, 465\n",
      "715, 573, 323, 297, 465\n",
      "716, 574, 324, 298, 466\n",
      "717, 575, 324, 298, 467\n",
      "718, 575, 324, 299, 467\n",
      "719, 575, 324, 299, 467\n",
      "720, 576, 324, 300, 468\n",
      "721, 576, 324, 300, 468\n",
      "722, 577, 325, 301, 469\n",
      "723, 578, 326, 301, 470\n",
      "724, 579, 327, 302, 471\n",
      "725, 579, 327, 302, 471\n",
      "726, 579, 328, 302, 472\n",
      "727, 579, 328, 302, 472\n",
      "728, 579, 328, 302, 472\n",
      "729, 580, 328, 303, 472\n",
      "730, 581, 328, 304, 472\n",
      "731, 582, 328, 305, 473\n",
      "732, 582, 328, 306, 474\n",
      "733, 583, 329, 307, 475\n",
      "734, 584, 329, 308, 475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735, 585, 330, 308, 476\n",
      "736, 586, 331, 308, 477\n",
      "737, 586, 331, 308, 477\n",
      "738, 587, 331, 309, 477\n",
      "739, 587, 331, 309, 477\n",
      "740, 588, 332, 310, 478\n",
      "741, 589, 332, 311, 479\n",
      "742, 589, 332, 312, 479\n",
      "743, 590, 333, 312, 480\n",
      "744, 591, 334, 312, 481\n",
      "745, 592, 335, 313, 481\n",
      "746, 593, 336, 314, 481\n",
      "747, 594, 336, 314, 481\n",
      "748, 595, 336, 315, 481\n",
      "749, 596, 336, 315, 481\n",
      "750, 597, 336, 315, 481\n",
      "751, 598, 337, 315, 481\n",
      "752, 599, 338, 316, 482\n",
      "753, 600, 338, 317, 482\n",
      "754, 601, 339, 317, 483\n",
      "755, 602, 339, 317, 484\n",
      "756, 603, 339, 317, 484\n",
      "757, 603, 339, 317, 484\n",
      "758, 604, 340, 318, 484\n",
      "759, 605, 341, 319, 485\n",
      "760, 606, 342, 319, 486\n",
      "761, 607, 342, 319, 486\n",
      "762, 608, 343, 319, 487\n",
      "763, 609, 344, 319, 488\n",
      "764, 609, 344, 319, 488\n",
      "765, 610, 344, 320, 489\n",
      "766, 611, 344, 321, 490\n",
      "767, 612, 345, 322, 491\n",
      "768, 613, 345, 323, 492\n",
      "769, 614, 345, 323, 493\n",
      "770, 614, 345, 323, 493\n",
      "771, 615, 346, 324, 494\n",
      "772, 615, 346, 324, 494\n",
      "773, 616, 347, 325, 495\n",
      "774, 617, 347, 326, 496\n",
      "775, 618, 347, 327, 497\n",
      "776, 619, 348, 327, 498\n",
      "777, 619, 348, 328, 498\n",
      "778, 620, 349, 328, 499\n",
      "779, 621, 350, 329, 500\n",
      "780, 622, 350, 329, 501\n",
      "781, 623, 351, 329, 502\n",
      "782, 624, 352, 330, 503\n",
      "783, 625, 353, 331, 504\n",
      "784, 626, 354, 331, 505\n",
      "785, 626, 354, 331, 506\n",
      "786, 627, 355, 331, 506\n",
      "787, 628, 356, 332, 507\n",
      "788, 629, 357, 332, 507\n",
      "789, 629, 357, 332, 507\n",
      "790, 630, 357, 332, 508\n",
      "791, 631, 357, 332, 509\n",
      "792, 632, 358, 332, 510\n",
      "793, 633, 358, 333, 511\n",
      "794, 634, 359, 333, 512\n",
      "795, 635, 359, 333, 513\n",
      "796, 636, 360, 333, 514\n",
      "797, 637, 360, 333, 515\n",
      "798, 638, 361, 334, 516\n",
      "799, 639, 361, 335, 517\n",
      "800, 640, 361, 335, 518\n",
      "801, 641, 361, 336, 518\n",
      "802, 642, 361, 337, 518\n",
      "803, 643, 362, 338, 519\n",
      "804, 644, 363, 338, 520\n",
      "805, 645, 363, 339, 521\n",
      "806, 646, 363, 339, 522\n",
      "807, 647, 364, 339, 523\n",
      "808, 648, 365, 340, 524\n",
      "809, 649, 366, 341, 525\n",
      "810, 649, 366, 342, 525\n",
      "811, 650, 367, 342, 525\n",
      "812, 651, 368, 343, 526\n",
      "813, 652, 368, 344, 527\n",
      "814, 653, 368, 345, 527\n",
      "815, 654, 369, 345, 528\n",
      "816, 655, 369, 346, 529\n",
      "817, 656, 369, 346, 529\n",
      "818, 656, 369, 346, 529\n",
      "819, 657, 369, 346, 529\n",
      "820, 657, 369, 346, 529\n",
      "821, 657, 369, 346, 529\n",
      "822, 658, 369, 347, 529\n",
      "823, 659, 370, 347, 530\n",
      "824, 659, 370, 347, 530\n",
      "825, 660, 371, 347, 531\n",
      "826, 661, 371, 348, 531\n",
      "827, 662, 372, 349, 531\n",
      "828, 663, 373, 350, 532\n",
      "829, 663, 373, 350, 532\n",
      "830, 664, 373, 351, 532\n",
      "831, 665, 374, 351, 533\n",
      "832, 666, 375, 351, 534\n",
      "833, 666, 375, 352, 534\n",
      "834, 667, 375, 353, 534\n",
      "835, 668, 375, 353, 535\n",
      "836, 669, 375, 353, 536\n",
      "837, 670, 375, 354, 537\n",
      "838, 671, 375, 354, 538\n",
      "839, 672, 376, 355, 539\n",
      "840, 673, 376, 355, 540\n",
      "841, 674, 376, 356, 540\n",
      "842, 675, 376, 357, 540\n",
      "843, 676, 376, 357, 540\n",
      "844, 677, 376, 357, 541\n",
      "845, 677, 376, 357, 541\n",
      "846, 678, 377, 357, 542\n",
      "847, 678, 377, 358, 542\n",
      "848, 679, 378, 358, 543\n",
      "849, 680, 379, 359, 544\n",
      "850, 681, 379, 359, 545\n",
      "851, 682, 380, 360, 546\n",
      "852, 683, 381, 360, 547\n",
      "853, 684, 381, 360, 548\n",
      "854, 685, 381, 360, 548\n",
      "855, 686, 382, 361, 549\n",
      "856, 687, 383, 362, 550\n",
      "857, 688, 384, 363, 550\n",
      "858, 688, 385, 364, 551\n",
      "859, 688, 385, 364, 551\n",
      "860, 689, 386, 364, 552\n",
      "861, 689, 386, 364, 552\n",
      "862, 689, 386, 364, 552\n",
      "863, 690, 387, 364, 553\n",
      "864, 691, 387, 365, 553\n",
      "865, 692, 388, 366, 554\n",
      "866, 693, 388, 367, 554\n",
      "867, 694, 388, 367, 555\n",
      "868, 695, 389, 367, 556\n",
      "869, 696, 389, 367, 557\n",
      "870, 697, 390, 368, 558\n",
      "871, 698, 391, 368, 558\n",
      "872, 699, 391, 369, 558\n",
      "873, 699, 391, 369, 559\n",
      "874, 700, 392, 369, 560\n",
      "875, 701, 393, 369, 561\n",
      "876, 702, 393, 370, 561\n",
      "877, 703, 394, 371, 562\n",
      "878, 704, 395, 371, 563\n",
      "879, 704, 395, 371, 563\n",
      "880, 705, 396, 372, 564\n",
      "881, 706, 397, 372, 565\n",
      "882, 707, 397, 372, 565\n",
      "883, 708, 398, 372, 566\n",
      "884, 709, 399, 372, 567\n",
      "885, 710, 400, 373, 568\n",
      "886, 711, 401, 374, 569\n",
      "887, 712, 402, 375, 570\n",
      "888, 713, 403, 375, 571\n",
      "889, 713, 403, 375, 571\n",
      "890, 714, 404, 375, 572\n",
      "891, 715, 405, 376, 573\n",
      "892, 716, 406, 376, 574\n",
      "893, 717, 406, 377, 575\n",
      "894, 717, 406, 378, 575\n",
      "895, 718, 406, 379, 576\n",
      "896, 719, 406, 379, 576\n",
      "897, 719, 406, 380, 576\n",
      "898, 719, 406, 381, 576\n",
      "899, 720, 406, 382, 577\n",
      "900, 721, 406, 382, 577\n",
      "901, 722, 406, 383, 577\n",
      "902, 723, 407, 383, 578\n",
      "903, 724, 407, 384, 579\n",
      "904, 725, 408, 384, 580\n",
      "905, 726, 409, 385, 581\n",
      "906, 727, 410, 385, 582\n",
      "907, 728, 410, 386, 582\n",
      "908, 728, 410, 387, 582\n",
      "909, 729, 410, 387, 583\n",
      "910, 729, 410, 387, 583\n",
      "911, 730, 411, 388, 584\n",
      "912, 731, 412, 388, 585\n",
      "913, 732, 412, 388, 585\n",
      "914, 733, 412, 389, 585\n",
      "915, 734, 412, 390, 586\n",
      "916, 735, 412, 391, 586\n",
      "917, 736, 412, 392, 587\n",
      "918, 737, 413, 393, 588\n",
      "919, 738, 413, 394, 589\n",
      "920, 738, 413, 394, 589\n",
      "921, 739, 414, 394, 590\n",
      "922, 740, 414, 394, 590\n",
      "923, 740, 414, 394, 590\n",
      "924, 741, 415, 395, 591\n",
      "925, 742, 416, 395, 592\n",
      "926, 743, 417, 395, 593\n",
      "927, 744, 418, 395, 594\n",
      "928, 745, 419, 396, 595\n",
      "929, 746, 419, 397, 596\n",
      "930, 747, 420, 398, 597\n",
      "931, 747, 420, 399, 597\n",
      "932, 748, 420, 399, 597\n",
      "933, 749, 421, 400, 598\n",
      "934, 750, 421, 400, 598\n",
      "935, 751, 421, 400, 599\n",
      "936, 752, 422, 401, 600\n",
      "937, 753, 422, 402, 600\n",
      "938, 753, 422, 402, 600\n",
      "939, 754, 422, 402, 601\n",
      "940, 755, 423, 402, 602\n",
      "941, 755, 423, 402, 602\n",
      "942, 756, 423, 402, 602\n",
      "943, 757, 424, 402, 603\n",
      "944, 758, 424, 402, 603\n",
      "945, 759, 425, 403, 604\n",
      "946, 760, 426, 404, 605\n",
      "947, 761, 427, 404, 605\n",
      "948, 762, 427, 405, 606\n",
      "949, 763, 427, 406, 607\n",
      "950, 764, 428, 406, 608\n",
      "951, 764, 428, 406, 608\n",
      "952, 765, 428, 406, 609\n",
      "953, 765, 428, 406, 609\n",
      "954, 766, 428, 406, 610\n",
      "955, 767, 429, 406, 611\n",
      "956, 768, 429, 406, 612\n",
      "957, 769, 430, 407, 613\n",
      "958, 770, 431, 408, 614\n",
      "959, 770, 431, 409, 614\n",
      "960, 771, 431, 410, 615\n",
      "961, 772, 432, 410, 616\n",
      "962, 773, 433, 411, 617\n",
      "963, 774, 433, 412, 617\n",
      "964, 774, 433, 412, 617\n",
      "965, 775, 434, 412, 618\n",
      "966, 776, 434, 413, 618\n",
      "967, 777, 435, 413, 619\n",
      "968, 778, 435, 414, 620\n",
      "969, 779, 436, 415, 621\n",
      "970, 780, 437, 415, 622\n",
      "971, 781, 438, 415, 623\n",
      "972, 782, 438, 416, 624\n",
      "973, 783, 439, 416, 625\n",
      "974, 784, 439, 417, 626\n",
      "975, 785, 439, 418, 626\n",
      "976, 785, 439, 418, 626\n",
      "977, 786, 439, 419, 627\n",
      "978, 786, 439, 419, 627\n",
      "979, 787, 439, 420, 628\n",
      "980, 788, 440, 421, 629\n",
      "981, 788, 440, 421, 629\n",
      "982, 789, 440, 422, 629\n",
      "983, 790, 441, 422, 630\n",
      "984, 790, 441, 422, 631\n",
      "985, 791, 441, 423, 631\n",
      "986, 792, 442, 423, 632\n",
      "987, 793, 442, 424, 633\n",
      "988, 793, 442, 425, 633\n",
      "989, 794, 443, 426, 634\n",
      "990, 794, 443, 426, 635\n",
      "991, 795, 444, 426, 636\n",
      "992, 795, 445, 426, 637\n",
      "993, 796, 446, 427, 638\n",
      "994, 797, 447, 427, 639\n",
      "995, 798, 448, 428, 639\n",
      "996, 798, 448, 429, 639\n",
      "997, 799, 449, 429, 640\n",
      "998, 800, 450, 429, 641\n",
      "999, 801, 450, 430, 641\n"
     ]
    }
   ],
   "source": [
    "time = 0\n",
    "referencetime = 0.1\n",
    "timea = 0\n",
    "timeb = 0\n",
    "timeg = 0\n",
    "countbest = 0\n",
    "counta = 0\n",
    "countb = 0\n",
    "countg = 0\n",
    "\n",
    "#for i in range(X_test.shape[0]):\n",
    "for i in range(1000):\n",
    "    \n",
    "    x = np.array([X_test[i,:]])\n",
    "    time += referencetime\n",
    "    timea += referencetime\n",
    "    timeb += referencetime\n",
    "    timeg += referencetime\n",
    "    \n",
    "    # Alpha-policy\n",
    "    x[:,9] = 1\n",
    "    x[:,10] = 0\n",
    "    x[:,11] = 0\n",
    "    ya = model.predict(x)[0,0]\n",
    "    \n",
    "     # Beta-policy\n",
    "    x[:,9] = 0\n",
    "    x[:,10] = 1 \n",
    "    x[:,11] = 0\n",
    "    yb = model.predict(x)[0,0]\n",
    "    \n",
    "     # Gamma-policy\n",
    "    x[:,9] = 0\n",
    "    x[:,10] = 0\n",
    "    x[:,11] = 1 \n",
    "    yg = model.predict(x)[0,0] \n",
    "    \n",
    "    if ya>yb and ya>yg:\n",
    "        policy = 'alpha'\n",
    "        precision = precisiona \n",
    "        y = ya\n",
    "    elif yb>ya and yb>yg:\n",
    "        policy = 'beta'\n",
    "        precision = precisionb\n",
    "        y = yb\n",
    "    else:\n",
    "        policy = 'gamma'\n",
    "        precision = precisiong\n",
    "        y = yg\n",
    "    \n",
    "    y = float(y)\n",
    "    \n",
    "    # Best policy\n",
    "    # print(f'Policy: {policy}, PIB: {y*100:0.2f}%, precision: {y*100:0.2f}%')\n",
    "    time += modeltime.predict(x)[0,0]\n",
    "    if np.random.random()<y and np.random.random()<precision: \n",
    "        # Correct inventory\n",
    "        countbest += 1\n",
    "    else:\n",
    "        # Inventory fault\n",
    "        time += 10 + 20*np.random.random() \n",
    "        \n",
    "    # Static policy alfa\n",
    "    x[:,9] = 1\n",
    "    x[:,10] = 0 \n",
    "    x[:,11] = 0 \n",
    "    y = model.predict(x)[0,0]\n",
    "    timea += modeltime.predict(x)[0,0]\n",
    "    if np.random.random()<y and np.random.random()<precisiona: \n",
    "            # Correct inventory\n",
    "            counta += 1\n",
    "    else:\n",
    "        # Inventory fault\n",
    "        timea += 10 + 20*np.random.random() \n",
    "        \n",
    "    # Static policy beta\n",
    "    x[:,9] = 0\n",
    "    x[:,10] = 1 \n",
    "    x[:,11] = 0\n",
    "    y = model.predict(x)[0,0]\n",
    "    timeb += modeltime.predict(x)[0,0]\n",
    "    if np.random.random()<y and np.random.random()<precisionb: \n",
    "            # Correct inventory\n",
    "            countb += 1\n",
    "    else:\n",
    "        # Inventory fault\n",
    "        timeb += 10 + 20*np.random.random() \n",
    "        \n",
    "    # Static policy gamma\n",
    "    x[:,9] = 0\n",
    "    x[:,10] = 0\n",
    "    x[:,11] = 1\n",
    "    y = model.predict(x)[0,0]\n",
    "    timeg += modeltime.predict(x)[0,0]\n",
    "    if np.random.random()<y and np.random.random()<precisiong: \n",
    "            # Correct inventory\n",
    "            countg += 1\n",
    "    else:\n",
    "        # Inventory fault\n",
    "        timeg += 10 + 20*np.random.random() \n",
    "        \n",
    "    #print(f'{i}, {time}, {timea}, {timeb}, {timeg}')\n",
    "    print(f'{i}, {countbest}, {counta}, {countb}, {countg}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "rfidml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1163px",
    "left": "1185.6px",
    "top": "111.133px",
    "width": "344.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
